{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jc4K2Me98TAR",
    "outputId": "8bfb9e1d-11c6-498f-8c9f-5fd6dcb6be70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Aug 26 22:00:08 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 536.99                 Driver Version: 536.99       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce MX110         WDDM  | 00000000:02:00.0 Off |                  N/A |\n",
      "| N/A    0C    P8              N/A / 200W |    139MiB /  2048MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1480    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      3780    C+G   ...l\\Microsoft\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A      9832    C+G   ...l\\Microsoft\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A     15796    C+G   ...64__8xx8rvfyw5nnt\\app\\Messenger.exe    N/A      |\n",
      "|    0   N/A  N/A     18132    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     19460    C+G   C:\\Windows\\System32\\dwm.exe               N/A      |\n",
      "|    0   N/A  N/A     23376    C+G   ...on\\116.0.1938.62\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     23812    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     29988    C+G   ...1.0_x64__t4vj0pshhgkwm\\Telegram.exe    N/A      |\n",
      "|    0   N/A  N/A     34252    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "2.3.0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "import os\n",
    "import datetime\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"     #use GPU-0\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "gpus=tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RrZYjdGv8lt5",
    "outputId": "540596ae-b432-46c9-a456-1c9c3f2d4226"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training images: 12\n",
      "number of valid images: 8\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "\n",
    "patch_size=48\n",
    "patch_num=300\n",
    "patch_threshold=25\n",
    "TRAIN_OR_VAL=0.6\n",
    "dataset_path='C:/Users/USER/Downloads/CVPR FINAL PROJECT/Project data set/'\n",
    "\n",
    "train_dir=dataset_path+\"training/\"\n",
    "\n",
    "train_image_dir=train_dir+\"images/\"\n",
    "train_mask_dir=train_dir+\"mask/\"\n",
    "train_groundtruth_dir=train_dir+\"1st_manual/\"\n",
    "train_patch_dir=train_dir+\"patch/\"\n",
    "\n",
    "\n",
    "train_image_path_list=glob(train_image_dir+\"*.tif\")\n",
    "\n",
    "\n",
    "val_image_path_list=random.sample(train_image_path_list,int(len(train_image_path_list)*(1-TRAIN_OR_VAL)))\n",
    "train_image_path_list=[i for i in train_image_path_list if i not in val_image_path_list]\n",
    "\n",
    "print(\"number of training images:\",len(train_image_path_list))\n",
    "print(\"number of valid images:\",len(val_image_path_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "F5lMy2j7_cyk"
   },
   "outputs": [],
   "source": [
    "def restrict_normalized(imgs,mask):\n",
    "    imgs_normalized = np.empty(imgs.shape)\n",
    "    imgs_std = np.std(imgs)\n",
    "    imgs_mean = np.mean(imgs)\n",
    "    imgs_normalized = (imgs-imgs_mean)/imgs_std\n",
    "    for i in range(imgs.shape[2]):\n",
    "        imgs_normalized[:,:,i] = ((imgs_normalized[:,:,i] - np.min(imgs_normalized[:,:,i])) / (np.max(imgs_normalized[:,:,i])-np.min(imgs_normalized[:,:,i])))*255\n",
    "    return imgs_normalized\n",
    "\n",
    "# CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "#adaptive histogram equalization is used. In this, image is divided into small blocks called \"tiles\" (tileSize is 8x8 by default in OpenCV). Then each of these blocks are histogram equalized as usual. So in a small area, histogram would confine to a small region (unless there is noise). If noise is there, it will be amplified. To avoid this, contrast limiting is applied. If any histogram bin is above the specified contrast limit (by default 40 in OpenCV), those pixels are clipped and distributed uniformly to other bins before applying histogram equalization. After equalization, to remove artifacts in tile borders, bilinear interpolation is applied\n",
    "def clahe_equalized(imgs):\n",
    "  clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "  imgs_equalized = np.empty(imgs.shape)\n",
    "  for i in range(imgs.shape[2]):\n",
    "    imgs_equalized[:,:,i] = clahe.apply(np.array(imgs[:,:,i], dtype = np.uint8))\n",
    "  return imgs_equalized\n",
    "\n",
    "def normalized(imgs):\n",
    "  imgs_normalized =np.empty(imgs.shape)\n",
    "  for i in range(imgs.shape[2]):\n",
    "    imgs_normalized[:,:,i] =cv2.equalizeHist(imgs[:,:,i])\n",
    "  return imgs_normalized\n",
    "\n",
    "def adjust_gamma(imgs, gamma=1.0):\n",
    "  invGamma = 1.0 / gamma\n",
    "  table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "  # apply gamma correction using the lookup table\n",
    "  new_imgs = np.empty(imgs.shape)\n",
    "  for i in range(imgs.shape[2]):\n",
    "    new_imgs[:,:,i] = cv2.LUT(np.array(imgs[:,:,i], dtype = np.uint8), table)\n",
    "  return new_imgs\n",
    "\n",
    "def preprocess(image,mask):\n",
    "\n",
    "  assert np.max(mask)==1\n",
    "  image=np.array(image)\n",
    "  image[:,:,0]=image[:,:,0]*mask\n",
    "  image[:,:,1]=image[:,:,1]*mask\n",
    "  image[:,:,2]=image[:,:,2]*mask\n",
    "\n",
    "  image=restrict_normalized(image,mask)\n",
    "  image=clahe_equalized(image)\n",
    "  image=adjust_gamma(image,1.2)\n",
    "  image=image/255.0\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qnoq2Vuh_hN4",
    "outputId": "af3cf011-3354-45e3-8c5a-1dc1f3b39a81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate the training patches: 100%|███████████████████████████████████████████████████| 12/12 [00:19<00:00,  1.59s/it]\n",
      "Generate the val patches: 100%|██████████████████████████████████████████████████████████| 8/8 [00:11<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "def check_coord(x,y,h,w,patch_size):\n",
    "  if x-patch_size/2>0 and x+patch_size/2<h and y-patch_size/2>0 and y+patch_size/2<w:\n",
    "    return True\n",
    "  return False\n",
    "\n",
    "def image2patch(image_path,patch_num,patch_size,training=True,show=True):\n",
    "  image_name=image_path.split(\"\\\\\")[-1].split(\"_\")[0]\n",
    "\n",
    "  image=plt.imread(image_path)\n",
    "\n",
    "  groundtruth=plt.imread(train_groundtruth_dir+image_name+\"_manual1.gif\")\n",
    "  groundtruth=np.where(groundtruth>0,1,0)\n",
    "\n",
    "  mask=plt.imread(train_mask_dir+image_name+\"_training_mask.gif\")\n",
    "  mask=np.where(mask>0,1,0)\n",
    "  \n",
    "  image=preprocess(image,mask)\n",
    "  #image_binary=0.8*image[:,:,1]+0.2*image[:,:,2]\n",
    "\n",
    "  image_show=image.copy()\n",
    "  groundtruth_show=np.zeros_like(image)\n",
    "  groundtruth_show[:,:,0]=groundtruth.copy()\n",
    "  groundtruth_show[:,:,1]=groundtruth.copy()\n",
    "  groundtruth_show[:,:,2]=groundtruth.copy()\n",
    "\n",
    "  sample_count=0\n",
    "  sample_index=0\n",
    "\n",
    "  sample_point=np.where(groundtruth==1)     # generate sample point\n",
    "\n",
    "  state = np.random.get_state()      # shuffle the coord\n",
    "  np.random.shuffle(sample_point[0])\n",
    "  np.random.set_state(state)\n",
    "  np.random.shuffle(sample_point[1])\n",
    "\n",
    "  patch_image_list=[]\n",
    "  patch_groundtruth_list=[]\n",
    "\n",
    "  while sample_count<patch_num and sample_index<len(sample_point[0]):\n",
    "    x,y=sample_point[0][sample_index],sample_point[1][sample_index]\n",
    "    if check_coord(x,y,image.shape[0],image.shape[1],patch_size):\n",
    "      if np.sum(mask[x-patch_size//2:x+patch_size//2,y-patch_size//2:y+patch_size//2])>patch_threshold:     #select according to the threshold\n",
    "\n",
    "        patch_image_binary=image[x-patch_size//2:x+patch_size//2,y-patch_size//2:y+patch_size//2,:]   # patch image\n",
    "        patch_groundtruth=groundtruth[x-patch_size//2:x+patch_size//2,y-patch_size//2:y+patch_size//2]       # patch mask\n",
    "        #patch_image_binary=np.asarray(0.25*patch_image[:,:,2]+0.75*patch_image[:,:,1])         # B*0.25+G*0.75, which enhance the vessel\n",
    "        patch_groundtruth=np.where(patch_groundtruth>0,255,0)\n",
    "\n",
    "        #patch_image_binary =cv2.equalizeHist((patch_image_binary*255.0).astype(np.uint8))/255.0\n",
    "\n",
    "        patch_image_list.append(patch_image_binary)    # patch image\n",
    "        patch_groundtruth_list.append(patch_groundtruth)             # patch mask\n",
    "        if show:\n",
    "          cv2.rectangle(image_show, (y-patch_size//2,x-patch_size//2,), (y+patch_size//2,x+patch_size//2), (0,1,0), 2)  #draw the illustration\n",
    "          cv2.rectangle(groundtruth_show, (y-patch_size//2,x-patch_size//2,), (y+patch_size//2,x+patch_size//2), (0,1,0), 2)\n",
    "        sample_count+=1\n",
    "\n",
    "    if show:                                 # visualize the sample process\n",
    "      plt.figure(figsize=(15,15))\n",
    "      plt.title(\"processing: %s\"%image_name)\n",
    "      plt.subplot(121)\n",
    "      plt.imshow(image_show,cmap=plt.cm.gray)   # processd image\n",
    "      plt.subplot(122)\n",
    "      plt.imshow(groundtruth_show,cmap=plt.cm.gray)  #groundtruth of the image, patch is showed as the green square\n",
    "      plt.show()\n",
    "      display.clear_output(wait=True)\n",
    "    sample_index+=1\n",
    "\n",
    "  for i in range(len(patch_image_list)):\n",
    "    if training==True:\n",
    "        plt.imsave(train_patch_dir+image_name+\"-\"+str(i)+\"-img.jpg\",patch_image_list[i])\n",
    "        #print(patch_mask_list[i])\n",
    "        plt.imsave(train_patch_dir+image_name+\"-\"+str(i)+\"-groundtruth.jpg\",(patch_groundtruth_list[i]/225.0).astype(np.uint8),cmap = plt.cm.gray)\n",
    "    else:\n",
    "        plt.imsave(train_patch_dir+image_name+\"_\"+str(i)+\"_val_img.jpg\",patch_image_list[i])\n",
    "        #print(patch_mask_list[i])\n",
    "        plt.imsave(train_patch_dir+image_name+\"_\"+str(i)+\"_val_groundtruth.jpg\",(patch_groundtruth_list[i]/225.0).astype(np.uint8),cmap = plt.cm.gray)\n",
    "\n",
    "# delete original patch images\n",
    "if not os.path.exists(train_patch_dir):\n",
    "  os.mkdir(train_patch_dir)\n",
    "else:\n",
    "  shutil.rmtree(train_patch_dir)\n",
    "  os.mkdir(train_patch_dir)\n",
    "\n",
    "# generate patch images\n",
    "for i in tqdm(range(len(train_image_path_list)),desc=\"Generate the training patches: \"):\n",
    "  image2patch(train_image_path_list[i],patch_num,patch_size,training=True,show=False)  # set show=True to visualize the sample process, which is much slower than show=False\n",
    "\n",
    "for i in tqdm(range(len(val_image_path_list)),desc=\"Generate the val patches: \"):\n",
    "  image2patch(val_image_path_list[i],patch_num,patch_size,training=False,show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JmvG0M-h_mje"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import AveragePooling2D,Conv2DTranspose,Input,Add,Conv2D, BatchNormalization,LeakyReLU, Activation, MaxPool2D, Dropout, Flatten, Dense,UpSampling2D,Concatenate,Softmax\n",
    "\n",
    "# define the model under eager mode\n",
    "\n",
    "class LinearTransform(tf.keras.Model):\n",
    "  def __init__(self, name=\"LinearTransform\"):\n",
    "    super(LinearTransform, self).__init__(self,name=name)\n",
    "\n",
    "    self.conv_r=Conv2D(1,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "    self.conv_g=Conv2D(1,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "    self.conv_b=Conv2D(1,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "\n",
    "    self.pool_rc=AveragePooling2D(pool_size=(patch_size,patch_size),strides=1)\n",
    "    self.pool_gc=AveragePooling2D(pool_size=(patch_size,patch_size),strides=1)\n",
    "    self.pool_bc=AveragePooling2D(pool_size=(patch_size,patch_size),strides=1)\n",
    "\n",
    "    self.bn=BatchNormalization()\n",
    "    self.sigmoid=Activation('sigmoid')\n",
    "    self.softmax=Activation('softmax')\n",
    "\n",
    "  def call(self, input,training=True):\n",
    "    r,g,b=input[:,:,:,0:1],input[:,:,:,1:2],input[:,:,:,2:3]\n",
    "\n",
    "    rs=self.conv_r(r)\n",
    "    gs=self.conv_g(g)\n",
    "    bs=self.conv_r(b)\n",
    "\n",
    "    rc=tf.reshape(self.pool_rc(rs),[-1,1])\n",
    "    gc=tf.reshape(self.pool_gc(gs),[-1,1])\n",
    "    bc=tf.reshape(self.pool_bc(bs),[-1,1])\n",
    "\n",
    "    merge=Concatenate(axis=-1)([rc,gc,bc])\n",
    "    merge=tf.expand_dims(merge,axis=1)\n",
    "    merge=tf.expand_dims(merge,axis=1)\n",
    "    merge=self.softmax(merge)\n",
    "    merge=tf.repeat(merge,repeats=48,axis=2)\n",
    "    merge=tf.repeat(merge,repeats=48,axis=1)\n",
    "\n",
    "    r=r*(1+self.sigmoid(rs))\n",
    "    g=g*(1+self.sigmoid(gs))\n",
    "    b=b*(1+self.sigmoid(bs))\n",
    "\n",
    "    output=self.bn(merge[:,:,:,0:1]*r+merge[:,:,:,1:2]*g+merge[:,:,:,2:3]*b,training=training)\n",
    "    return output\n",
    "\n",
    "class ResBlock(tf.keras.Model):\n",
    "  def __init__(self,out_ch,residual_path=False,stride=1):\n",
    "    super(ResBlock,self).__init__(self)\n",
    "    self.residual_path=residual_path\n",
    "\n",
    "    self.conv1=Conv2D(out_ch,kernel_size=3,strides=stride,padding='same', use_bias=False,data_format=\"channels_last\")\n",
    "    self.bn1=BatchNormalization()\n",
    "    self.relu1=LeakyReLU()#Activation('leaky_relu')\n",
    "\n",
    "    self.conv2=Conv2D(out_ch,kernel_size=3,strides=1,padding='same', use_bias=False,data_format=\"channels_last\")\n",
    "    self.bn2=BatchNormalization()\n",
    "\n",
    "    if residual_path:\n",
    "      self.conv_shortcut=Conv2D(out_ch,kernel_size=1,strides=stride,padding='same',use_bias=False)\n",
    "      self.bn_shortcut=BatchNormalization()\n",
    "\n",
    "    self.relu2=LeakyReLU()#Activation('leaky_relu')\n",
    "\n",
    "  def call(self,x,training=True):\n",
    "    xs=self.relu1(self.bn1(self.conv1(x),training=training))\n",
    "    xs=self.bn2(self.conv2(xs),training=training)\n",
    "\n",
    "    if self.residual_path:\n",
    "      x=self.bn_shortcut(self.conv_shortcut(x),training=training)\n",
    "    #print(x.shape,xs.shape)\n",
    "    xs=x+xs\n",
    "    return self.relu2(xs)\n",
    "\n",
    "\n",
    "class Unet(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(Unet,self).__init__(self)\n",
    "    self.conv_init=LinearTransform()\n",
    "    self.resinit=ResBlock(16,residual_path=True)\n",
    "    self.up_sample=UpSampling2D(size=(2,2),interpolation='bilinear')\n",
    "    self.resup=ResBlock(32,residual_path=True)\n",
    "\n",
    "    self.pool1=MaxPool2D(pool_size=(2,2))\n",
    "\n",
    "    self.resblock_down1=ResBlock(64,residual_path=True)\n",
    "    self.resblock_down11=ResBlock(64,residual_path=False)\n",
    "    self.pool2=MaxPool2D(pool_size=(2,2))\n",
    "\n",
    "    self.resblock_down2=ResBlock(128,residual_path=True)\n",
    "    self.resblock_down21=ResBlock(128,residual_path=False)\n",
    "    self.pool3=MaxPool2D(pool_size=(2,2))\n",
    "\n",
    "    self.resblock_down3=ResBlock(256,residual_path=True)\n",
    "    self.resblock_down31=ResBlock(256,residual_path=False)\n",
    "    self.pool4=MaxPool2D(pool_size=(2,2))\n",
    "\n",
    "    self.resblock=ResBlock(512,residual_path=True)\n",
    "\n",
    "    self.unpool3=UpSampling2D(size=(2,2),interpolation='bilinear')\n",
    "    self.resblock_up3=ResBlock(256,residual_path=True)\n",
    "    self.resblock_up31=ResBlock(256,residual_path=False)\n",
    "\n",
    "    self.unpool2=UpSampling2D(size=(2,2),interpolation='bilinear')\n",
    "    self.resblock_up2=ResBlock(128,residual_path=True)\n",
    "    self.resblock_up21=ResBlock(128,residual_path=False)\n",
    "\n",
    "    self.unpool1=UpSampling2D(size=(2,2),interpolation='bilinear')\n",
    "    self.resblock_up1=ResBlock(64,residual_path=True)\n",
    "\n",
    "    self.unpool_final=UpSampling2D(size=(2,2),interpolation='bilinear')\n",
    "    self.resblock2=ResBlock(32,residual_path=True)\n",
    "\n",
    "    self.pool_final=MaxPool2D(pool_size=(2,2))\n",
    "    self.resfinal=ResBlock(32)\n",
    "\n",
    "    self.conv_final=Conv2D(1,kernel_size=1,strides=1,padding='same',use_bias=False)\n",
    "    self.bn_final=BatchNormalization()\n",
    "    self.act=Activation('sigmoid')\n",
    "\n",
    "  def call(self,x,training=True):\n",
    "    x_linear=self.conv_init(x,training=training)\n",
    "    x=self.resinit(x_linear,training=training)\n",
    "    x=self.up_sample(x)\n",
    "    x=self.resup(x,training=training)\n",
    "\n",
    "    stage1=self.pool1(x)\n",
    "    stage1=self.resblock_down1(stage1,training=training)\n",
    "    stage1=self.resblock_down11(stage1,training=training)\n",
    "\n",
    "    stage2=self.pool2(stage1)\n",
    "    stage2=self.resblock_down2(stage2,training=training)\n",
    "    stage2=self.resblock_down21(stage2,training=training)\n",
    "\n",
    "    stage3=self.pool3(stage2)\n",
    "    stage3=self.resblock_down3(stage3,training=training)\n",
    "    stage3=self.resblock_down31(stage3,training=training)\n",
    "\n",
    "    stage4=self.pool4(stage3)\n",
    "    stage4=self.resblock(stage4,training=training)\n",
    "\n",
    "    stage3=Concatenate(axis=3)([stage3,self.unpool3(stage4)])\n",
    "    stage3=self.resblock_up3(stage3,training=training)\n",
    "    stage3=self.resblock_up31(stage3,training=training)\n",
    "\n",
    "    stage2=Concatenate(axis=3)([stage2,self.unpool2(stage3)])\n",
    "    stage2=self.resblock_up2(stage2,training=training)\n",
    "    stage2=self.resblock_up21(stage2,training=training)\n",
    "\n",
    "    stage1=Concatenate(axis=3)([stage1,self.unpool1(stage2)])\n",
    "    stage1=self.resblock_up1(stage1,training=training)\n",
    "\n",
    "    x=Concatenate(axis=3)([x,self.unpool_final(stage1)])\n",
    "    x=self.resblock2(x,training=training)\n",
    "\n",
    "    x=self.pool_final(x)\n",
    "    x=self.resfinal(x,training=training)\n",
    "\n",
    "    seg_result=self.act(self.bn_final(self.conv_final(x),training=training))\n",
    "\n",
    "    return x_linear,seg_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qBkzGvdjAFQP"
   },
   "outputs": [],
   "source": [
    "EPOCHS=5\n",
    "VAL_TIME=2\n",
    "LR=0.0001\n",
    "BATCH_SIZE=25\n",
    "\n",
    "checkpoint_path=dataset_path+\"ckpt/\"\n",
    "log_path=dataset_path+\"logs/\"\n",
    "\n",
    "if not os.path.exists(checkpoint_path):\n",
    "  os.mkdir(checkpoint_path)\n",
    "\n",
    "if not os.path.exists(log_path):\n",
    "  os.mkdir(log_path)\n",
    "\n",
    "# use tensorboard to visualize the loss,acc,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AMaxmCQzAJJ-",
    "outputId": "35608dca-f253-44bf-db81-67432d4d7083"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600 3600\n",
      "['C:/Users/USER/Downloads/CVPR FINAL PROJECT/Project data set/training/patch\\\\29-191-img.jpg', 'C:/Users/USER/Downloads/CVPR FINAL PROJECT/Project data set/training/patch\\\\28-197-img.jpg']\n",
      "['C:/Users/USER/Downloads/CVPR FINAL PROJECT/Project data set/training/patch\\\\29-191-groundtruth.jpg', 'C:/Users/USER/Downloads/CVPR FINAL PROJECT/Project data set/training/patch\\\\28-197-groundtruth.jpg']\n",
      "['C:/Users/USER/Downloads/CVPR FINAL PROJECT/Project data set/training/patch\\\\21_0_val_img.jpg', 'C:/Users/USER/Downloads/CVPR FINAL PROJECT/Project data set/training/patch\\\\21_100_val_img.jpg']\n",
      "['C:/Users/USER/Downloads/CVPR FINAL PROJECT/Project data set/training/patch\\\\21_0_val_groundtruth.jpg', 'C:/Users/USER/Downloads/CVPR FINAL PROJECT/Project data set/training/patch\\\\21_100_val_groundtruth.jpg']\n"
     ]
    }
   ],
   "source": [
    "def load_image_groundtruth(img_path,groundtruth_path):\n",
    "  img=tf.io.read_file(img_path)\n",
    "  img=tf.image.decode_jpeg(img,channels=3)\n",
    "  img=tf.image.resize(img,[patch_size,patch_size])\n",
    "\n",
    "  groundtruth=tf.io.read_file(groundtruth_path)\n",
    "  groundtruth=tf.image.decode_jpeg(groundtruth,channels=1)\n",
    "\n",
    "  # data argument\n",
    "  if random.uniform(0,1)>=0.5:\n",
    "    img=tf.image.flip_left_right(img)\n",
    "    groundtruth=tf.image.flip_left_right(groundtruth)\n",
    "\n",
    "  img=tf.image.resize(img,[patch_size,patch_size])\n",
    "  groundtruth=tf.image.resize(groundtruth,[patch_size,patch_size])\n",
    "\n",
    "  img/=255.0\n",
    "  groundtruth=(groundtruth+40)/255.0\n",
    "  groundtruth=tf.cast(groundtruth,dtype=tf.uint8)\n",
    "\n",
    "  return img,groundtruth\n",
    "\n",
    "\n",
    "train_patch_img_path_list=sorted(glob(train_patch_dir+\"*-*-img.jpg\"))\n",
    "train_patch_groundtruth_path_list=sorted(glob(train_patch_dir+\"*-*-groundtruth.jpg\"))\n",
    "train_patch_img_path_list,train_patch_groundtruth_path_list=shuffle(train_patch_img_path_list,train_patch_groundtruth_path_list,random_state=0)\n",
    "\n",
    "# make sure that img-list and mask-list is in order\n",
    "print(len(train_patch_img_path_list),len(train_patch_groundtruth_path_list))\n",
    "print(train_patch_img_path_list[:2])\n",
    "print(train_patch_groundtruth_path_list[:2])\n",
    "\n",
    "val_patch_img_path_list=sorted(glob(train_patch_dir+\"*_*_val_img.jpg\"))\n",
    "val_patch_groundtruth_path_list=sorted(glob(train_patch_dir+\"*_*_val_groundtruth.jpg\"))\n",
    "\n",
    "print(val_patch_img_path_list[:2])\n",
    "print(val_patch_groundtruth_path_list[:2])\n",
    "\n",
    "# Training Dataloader\n",
    "train_dataset=tf.data.Dataset.from_tensor_slices((train_patch_img_path_list,train_patch_groundtruth_path_list))\n",
    "train_dataset=train_dataset.map(load_image_groundtruth,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1300).prefetch(BATCH_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "# VAL Dataloader\n",
    "val_dataset=tf.data.Dataset.from_tensor_slices((val_patch_img_path_list,val_patch_groundtruth_path_list))\n",
    "val_dataset=val_dataset.map(load_image_groundtruth,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "val_dataset =val_dataset.shuffle(buffer_size=1300).prefetch(BATCH_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4X0VuWGmAR5V"
   },
   "outputs": [],
   "source": [
    "model=Unet()\n",
    "\n",
    "# Learning rate and optimizer\n",
    "cosine_decay = tf.keras.experimental.CosineDecayRestarts(initial_learning_rate=LR, first_decay_steps=12000,t_mul=1000,m_mul=0.5,alpha=1e-5)\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=cosine_decay)\n",
    "\n",
    "# loss function\n",
    "loss=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "# metric record\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_acc=tf.keras.metrics.Mean(name='train_acc')\n",
    "current_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n",
    "\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "val_acc=tf.keras.metrics.Mean(name='val_acc')\n",
    "val_accuracy = tf.keras.metrics.BinaryAccuracy(name='val_accuracy')\n",
    "\n",
    "# checkpoint\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "#ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=3)\n",
    "#ckpt.restore(tf.train.latest_checkpoint(checkpoint_path))\n",
    "\n",
    "# tensorboard writer\n",
    "log_dir=log_path+ datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_writer = tf.summary.create_file_writer(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GAxYdcESAXoa"
   },
   "outputs": [],
   "source": [
    "def dice(y_true,y_pred,smooth=1.):\n",
    "  y_true=tf.cast(y_true,dtype=tf.float32)\n",
    "  y_true_f = K.flatten(y_true)\n",
    "  y_pred_f = K.flatten(y_pred)\n",
    "  intersection = K.sum(y_true_f * y_pred_f)\n",
    "  return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true,y_pred):\n",
    "  return (1-dice(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NMK2sYj3AbeF"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_step(step,patch,groundtruth):\n",
    "  with tf.GradientTape() as tape:\n",
    "\n",
    "    linear,pred_seg=model(patch,training=True)\n",
    "    losses = dice_loss(groundtruth, pred_seg)\n",
    "\n",
    "  # calculate the gradient\n",
    "  grads = tape.gradient(losses, model.trainable_variables)\n",
    "  # bp\n",
    "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "  # record the training loss and accuracy\n",
    "  train_loss.update_state(losses)\n",
    "  train_acc.update_state(dice(groundtruth, pred_seg))\n",
    "\n",
    "\n",
    "\n",
    "def val_step(step,patch,groundtruth):\n",
    "\n",
    "  linear,pred_seg=model(patch,training=False)\n",
    "  losses = dice_loss(groundtruth, pred_seg)\n",
    "\n",
    "  # record the val loss and accuracy\n",
    "  val_loss.update_state(losses)\n",
    "  val_acc.update_state(dice(groundtruth, pred_seg))\n",
    "\n",
    "  tf.summary.image(\"image\",patch,step=step)\n",
    "  tf.summary.image(\"image transform\",linear,step=step)\n",
    "  tf.summary.image(\"groundtruth\",groundtruth*255,step=step)\n",
    "  tf.summary.image(\"pred\",pred_seg,step=step)\n",
    "  log_writer.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "ZMCDINvJAeft",
    "outputId": "ea3e6924-ae62-46be-ae92-653b45f35a09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, batch 143, loss:0.5315, dice:0.4685\n",
      "epoch 2, batch 95, train_loss:0.5147, train_dice:0.4853, val_loss:0.6067, val_dice:0.3933\n",
      "epoch 3, batch 143, loss:0.5073, dice:0.4927\n",
      "epoch 4, batch 95, train_loss:0.5007, train_dice:0.4993, val_loss:0.5343, val_dice:0.4657\n",
      "epoch 5, batch 143, loss:0.4955, dice:0.5045\n"
     ]
    }
   ],
   "source": [
    "lr_step = 0\n",
    "last_val_loss = 1e6\n",
    "with log_writer.as_default():\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Get the current learning rate for this epoch\n",
    "        learning_rate = optimizer.lr(epoch)\n",
    "        tf.summary.scalar(\"learning_rate\", learning_rate, step=epoch)\n",
    "\n",
    "        # renew the recorder\n",
    "        train_loss.reset_states()\n",
    "        train_acc.reset_states()\n",
    "        val_loss.reset_states()\n",
    "        val_acc.reset_states()\n",
    "\n",
    "        # training\n",
    "        for tstep, (patch, groundtruth) in enumerate(train_dataset):\n",
    "            train_step(lr_step, patch, groundtruth)\n",
    "            print('\\repoch {}, batch {}, loss:{:.4f}, dice:{:.4f}'.format(epoch + 1, tstep, train_loss.result(), train_acc.result()), end=\"\")\n",
    "            lr_step += 1\n",
    "\n",
    "        if (epoch + 1) % VAL_TIME == 0:\n",
    "            # Validation\n",
    "            for vstep, (patch, groundtruth) in enumerate(val_dataset):\n",
    "                val_step(lr_step, patch, groundtruth)\n",
    "\n",
    "            print('\\repoch {}, batch {}, train_loss:{:.4f}, train_dice:{:.4f}, val_loss:{:.4f}, val_dice:{:.4f}'.format(epoch + 1, vstep, train_loss.result(), train_acc.result(), val_loss.result(), val_acc.result()), end=\"\")\n",
    "            tf.summary.scalar(\"val_loss\", val_loss.result(), step=epoch)\n",
    "            tf.summary.scalar(\"val_acc\", val_acc.result(), step=epoch)\n",
    "\n",
    "            if val_loss.result() < last_val_loss:\n",
    "                ckpt.save(checkpoint_path)\n",
    "                last_val_loss = val_loss.result()\n",
    "        print(\"\")\n",
    "        tf.summary.scalar(\"train_loss\", train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar(\"train_acc\", train_acc.result(), step=epoch)\n",
    "        log_writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
